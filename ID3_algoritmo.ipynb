{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting numpy\n",
      "  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/16/2e/86f24451c2d530c88daf997cb8d6ac622c1d40d19f5a031ed68a4b73a374/numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/61.0 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/61.0 kB 222.6 kB/s eta 0:00:01\n",
      "     ------------------------- ------------ 41.0/61.0 kB 330.3 kB/s eta 0:00:01\n",
      "     -------------------------------------- 61.0/61.0 kB 362.9 kB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/15.5 MB 6.3 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.6/15.5 MB 7.5 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 1.1/15.5 MB 8.8 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.8/15.5 MB 10.2 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.6/15.5 MB 11.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.7/15.5 MB 13.8 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 5.0/15.5 MB 16.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 6.8/15.5 MB 18.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.0/15.5 MB 22.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.2/15.5 MB 23.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.2/15.5 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.1/15.5 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 27.3 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/22/a5/a0b255295406ed54269814bc93723cfd1a0da63fb9aaf99e1364f07923e5/pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\b47133\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\b47133\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/65/58/f9c9e6be752e9fcb8b6a0ee9fb87e6e7a1f6bcab2cdc73f02bb7ba91ada0/tzdata-2024.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\b47133\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/11.5 MB 5.0 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.8/11.5 MB 8.5 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.6/11.5 MB 11.0 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.3/11.5 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.5/11.5 MB 11.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.0/11.5 MB 14.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.0/11.5 MB 14.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.1/11.5 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.8/11.5 MB 17.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.5 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.5 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 19.8 MB/s eta 0:00:00\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "   ---------------------------------------- 0.0/505.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 505.5/505.5 kB 31.0 MB/s eta 0:00:00\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "   ---------------------------------------- 0.0/345.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 345.4/345.4 kB 20.9 MB/s eta 0:00:00\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base para todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_mechanism_geral(data, score_func, list_outputs, epsilon, global_sensivity):\n",
    "    scores = [score_func(data, out) for out in list_outputs]\n",
    "    probs = [np.exp(epsilon * score / (2 * global_sensivity)) for score in scores]\n",
    "    probs_normalizadas = probs / np.linalg.norm(probs, ord=1)\n",
    "\n",
    "    return np.random.choice(list_outputs, 1, p=probs_normalizadas)[0]\n",
    "\n",
    "def dampening_function(data, output, score_func, delta_func):\n",
    "    def b_func(data, i, output):\n",
    "        if i == 0:\n",
    "            return 0\n",
    "        return sum([delta_func(data, j, output) for j in range(i - 1)])\n",
    "    \n",
    "    i = 0  \n",
    "    score = score_func(data, output)\n",
    "    while True:\n",
    "        b_i = b_func(data, i, output)\n",
    "        b_ipp = b_func(data, i + 1, output)\n",
    "        if (score > 0 and (score < b_i or score >= b_ipp)) or (score < 0 and (score < -b_ipp or score >= -b_i)):\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        return (score - b_i) / (b_ipp - b_i) + i if score > 0 else (score + b_i) / (-b_ipp + b_i) - i\n",
    "\n",
    "def local_dampening_mechanism(data, epsilon, score_func, delta_func, list_outputs):\n",
    "    scores = [dampening_function(data, out, score_func, delta_func) for out in list_outputs]\n",
    "    probs = [np.exp(epsilon * score / 2) for score in scores]\n",
    "    probs_normalizadas = probs / np.linalg.norm(probs, ord=1)\n",
    "\n",
    "    return np.random.choice(list_outputs, 1, p=probs_normalizadas)[0]\n",
    "\n",
    "\n",
    "def permute_and_flip(data, epsilon, score_func, list_outputs, max_u):\n",
    "    max_score = max([score_func(data, out) for out in list_outputs])\n",
    "    # aqui talvez seja interessante copiar e passar a copia da list_ouputs\n",
    "    np.random.shuffle(list_outputs)\n",
    "    for r in list_outputs:\n",
    "        prob = np.exp(epsilon * (score_func(data, r) - max_score) / (2 * max_u))\n",
    "        if np.random.rand() < prob:\n",
    "            return r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_canditates(data, t, value_column, target, coluna, label):\n",
    "    # se a distancia for 0\n",
    "    if t == 0:\n",
    "      # dataframe onde o atributo A possui valor j\n",
    "      ## no caso, a coluna possui value_column\n",
    "      qtd_T_value_columnA = data[data[coluna] == value_column]\n",
    "      # dataframe onde o atributo A possui valor j e alvo é c de C\n",
    "      ## no caso, a coluna possui value_column e o label é oque procuramos\n",
    "      value_columnA_target = qtd_T_value_columnA[qtd_T_value_columnA[label] == target]\n",
    "\n",
    "      return qtd_T_value_columnA.shape[0], value_columnA_target.shape[0]\n",
    "    candidates = get_canditates(data, t-1, value_column, target, coluna, label)\n",
    "    validos_candidates = []\n",
    "\n",
    "    for x, y in candidates:\n",
    "      if x > 0 and y > 0:\n",
    "        validos_candidates.append((x - 1, y - 1))\n",
    "      if x < data.shape[0]:\n",
    "        validos_candidates.append((x + 1, y))\n",
    "    return validos_candidates\n",
    "\n",
    "def h_func(x, y):\n",
    "    def f_func(x, somar = False):\n",
    "        return x * np.log2((x + 1) / x) + np.log2(x + 1) if somar else x * np.log2((x - 1) / x) - np.log2(x - 1)\n",
    "    return max(f_func(x, True) - f_func(y, True), f_func(x) - f_func(y))\n",
    "\n",
    "def local_sensivity_at_tDistance(data:pd.DataFrame, t:float, col_val, target):\n",
    "    '''\n",
    "    data = dataframe\n",
    "\n",
    "    t = distâncuia\n",
    "\n",
    "    col_val = uma coluna do dataframe\n",
    "\n",
    "    target_values = lista com todas saídas possíveis do label\n",
    "    '''\n",
    "    H = []\n",
    "    for a in data[col_val].unique():\n",
    "      # iterar sobre as classes daquela coluna\n",
    "      for c in data[target].unique():\n",
    "        # ver os candidatos\n",
    "        candidates = get_canditates(data, t, a, c, col_val, target)\n",
    "        # para cada candidato, calcular a h_func e add a H\n",
    "        for x, y in candidates:\n",
    "          H.append(h_func(x,y))\n",
    "    # retoanr o maior valor H (entropy)\n",
    "    return max(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_count():\n",
    "    pass\n",
    "\n",
    "def utility_exp_7alg(data, colun_b, target):\n",
    "    lista = []\n",
    "    for val in data[colun_b].unique():\n",
    "      for out in data[target].unique():\n",
    "        data_B_val = data[data[colun_b] == val]\n",
    "        data_B_val_out_C = [data_B_val[target] == out]\n",
    "        tau_A = data_B_val.shape[0]\n",
    "        tau_Ac = data_B_val_out_C.shape[0]\n",
    "        lista.append(tau_Ac * np.log2(tau_Ac / tau_A))\n",
    "    return - sum(lista)\n",
    "\n",
    "def build_diff_PID3(data:pd.DataFrame, list_columns: list, target, profundidade, epsilon):\n",
    "    list_columns.remove(target)\n",
    "    t_val = max([len(data[col].unique()) for col in list_columns])\n",
    "    N_t = noisy_count()\n",
    "    data_target_list = data[target].unique()\n",
    "    if len(list_columns) == 0 or profundidade == 0 or N_t / (t_val * len(data_target_list)) < np.sqrt(2)/2:\n",
    "      data_output_partitions = [noisy_count(data[data[target] == c]) for c in data_target_list]\n",
    "      max_Nc = max(data_output_partitions)\n",
    "      # aqui DEVE ser retornado uma folha \"labeled with argmax c Nc\"\n",
    "      # não sei fazer isso\n",
    "      return max_Nc, data_output_partitions.index(max_Nc)\n",
    "    # columns_hat = local_dampening_mechanism(data, epsilon, ig_func, local_sensivity_at_tDistance, data_target_list)\n",
    "    columns_hat = exp_mechanism_geral(data, epsilon, ig_func, local_sensivity_at_tDistance, data_target_list)\n",
    "    data_i = [data[data[columns_hat] == i] for i in data[columns_hat].unique()]\n",
    "    sub_tree = []\n",
    "    for i in data_i:\n",
    "      sub_tree_i = partition(i, list_columns - columns_hat, target, d - 1, epsilon)\n",
    "      sub_tree.append(sub_tree_i)\n",
    "    \n",
    "    # AQUI DEVEMOS RETORNA UMA ARVORE COM UM NO RAIZ CHAMADO DE columns_hat e arestas chamada de 1 para columns_hat, cada uma indo para a subtree_i\n",
    "    return 0\n",
    "\n",
    "def global_diff_PID3(data:pd.DataFrame, target, profundidade: int, privacy_budget: float):\n",
    "    '''\n",
    "    data = um dataframe\n",
    "    target = a coluna alvo, no exemplo do tempo, seria o Y e o N\n",
    "    profundidade = numero que indica a profuntidade\n",
    "    privacy_budget = nivel de privacidade numero\n",
    "    '''\n",
    "    epsilon = privacy_budget / (2 * (profundidade + 1))\n",
    "    # NOTA: tem que remover a coluna alvo de data.columns.\n",
    "    return build_diff_PID3(data, data.columns, target, profundidade, epsilon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
